# app.py
# ---------------------------------------------
# ì§€ë„í•™ìŠµ ì‹¤ìŠµìš© Streamlit ì›¹ ì•±
# - CSV ì—…ë¡œë“œ â†’ íŠ¹ì§•/íƒ€ê¹ƒ ì„ íƒ â†’ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ â†’ ë¶„ë¥˜/íšŒê·€ ì„ íƒ â†’ ëª¨ë¸ í•™ìŠµ/í‰ê°€
# ---------------------------------------------
from pandas.errors import EmptyDataError
import streamlit as st
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score,
    confusion_matrix,
    classification_report,
    mean_squared_error,
    mean_absolute_error,
    r2_score,
    precision_score,
    recall_score,
    f1_score,
)


from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.preprocessing import StandardScaler, MinMaxScaler

import plotly.express as px


# ---------------------------------------------
# ê¸°ë³¸ ì„¤ì •
# ---------------------------------------------
st.set_page_config(
    page_title="ì§€ë„í•™ìŠµ ì‹¤ìŠµ ì•±",
    page_icon="ğŸ¤–",
    layout="wide",
)


# ---------------------------------------------
# 0. ìœ í‹¸ í•¨ìˆ˜ë“¤
# ---------------------------------------------
def load_data(uploaded_file):
    """CSV íŒŒì¼ì„ ì½ì–´ DataFrameìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ (ì¸ì½”ë”©/ë¹ˆ íŒŒì¼ ì˜ˆì™¸ ì²˜ë¦¬ í¬í•¨)"""
    if uploaded_file is None:
        return None

    try:
        # ì²« ë²ˆì§¸ ì‹œë„ ì „ì— í•­ìƒ íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ëŒë ¤ë†“ê¸°
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file)
        return df

    except UnicodeDecodeError:
        # ì¸ì½”ë”© ë¬¸ì œë¡œ ì‹¤íŒ¨í–ˆìœ¼ë©´ cp949ë¡œ ë‹¤ì‹œ ì‹œë„
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, encoding="cp949")
        return df

    except EmptyDataError:
        # íŒŒì¼ì´ ë¹„ì–´ìˆì„ ë•Œ
        st.error("CSV íŒŒì¼ì— **ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.** ë‚´ìš©ì´ ìˆëŠ” CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        return None

    except Exception as e:
        # ê·¸ ì™¸ ì˜ˆì™¸ëŠ” ë©”ì‹œì§€ë§Œ ë³´ì—¬ì£¼ê³  None ë°˜í™˜
        st.error(f"CSVë¥¼ ì½ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None


def show_data_overview(df):
    """ë°ì´í„°í”„ë ˆì„ ê¸°ë³¸ ì •ë³´ ì¶œë ¥"""
    st.subheader("1ï¸âƒ£ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(df.head(10), use_container_width=True)

    st.markdown("#### ğŸ“ ë°ì´í„° ìš”ì•½ ì •ë³´")
    col1, col2 = st.columns(2)

    with col1:
        st.write(f"- í–‰(row) ê°œìˆ˜: **{df.shape[0]}**")
        st.write(f"- ì—´(column) ê°œìˆ˜: **{df.shape[1]}**")
        st.write("- ì—´ ì´ë¦„:")
        st.write(list(df.columns))

    with col2:
        st.write("ğŸ” ê²°ì¸¡ì¹˜ ê°œìˆ˜ (ì—´ë³„):")
        st.write(df.isna().sum())


def show_correlation_heatmap(df):
    """ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ"""
    st.subheader("2ï¸âƒ£ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ")

    numeric_df = df.select_dtypes(include=[np.number])

    if numeric_df.shape[1] < 2:
        st.info("ìˆ˜ì¹˜í˜• ì—´ì´ 2ê°œ ì´ìƒ ìˆì–´ì•¼ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µì„ ê·¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    corr = numeric_df.corr()

    fig = px.imshow(
        corr,
        text_auto=True,
        color_continuous_scale="RdBu",
        zmin=-1,
        zmax=1,
        aspect="auto",
        labels=dict(color="ìƒê´€ê³„ìˆ˜"),
    )
    fig.update_layout(height=500)
    st.plotly_chart(fig, use_container_width=True)

    st.caption(
        "ìƒê´€ê³„ìˆ˜ëŠ” -1ì—ì„œ 1 ì‚¬ì´ì˜ ê°’ì´ë©°, ì ˆëŒ“ê°’ì´ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë‘ ë³€ìˆ˜ì˜ ì„ í˜• ê´€ê³„ê°€ ê°•í•©ë‹ˆë‹¤.\n"
        "ë‹¨, **ìƒê´€ê´€ê³„ê°€ ê³§ ì¸ê³¼ê´€ê³„(ì›ì¸-ê²°ê³¼)ë¥¼ ì˜ë¯¸í•˜ëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤.**"
    )


def show_target_correlations(df, target_col):
    """
    íƒ€ê¹ƒ ë³€ìˆ˜ì™€ ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ì˜ ê´€ë ¨ì„±ì„ ë³´ì—¬ì£¼ëŠ” í•¨ìˆ˜.
    - ìˆ˜ì¹˜í˜• íŠ¹ì§•: í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜
    - ë²”ì£¼í˜• íŠ¹ì§•(object, category): ì›-í•« ì¸ì½”ë”© í›„, íƒ€ê¹ƒê³¼ ê°€ì¥ ê´€ë ¨ì´ í° ë”ë¯¸ì˜ ìƒê´€ê³„ìˆ˜ë¥¼ ëŒ€í‘œê°’ìœ¼ë¡œ ì‚¬ìš©
    """
    st.subheader("3ï¸âƒ£ íƒ€ê¹ƒ ë³€ìˆ˜ì™€ì˜ ê´€ë ¨ë„ (ìˆ˜ì¹˜í˜• + ë²”ì£¼í˜•)")

    if target_col is None:
        st.info("íƒ€ê¹ƒ ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ë©´, íƒ€ê¹ƒê³¼ ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ì˜ ê´€ë ¨ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        return

    y = df[target_col]

    # íƒ€ê¹ƒì´ ìˆ˜ì¹˜í˜•/ì´ì§„(0/1)ì´ì–´ì•¼ ìƒê´€ê³„ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ë³´ê¸° ì‰¬ì›€
    if not np.issubdtype(y.dtype, np.number):
        try:
            y = pd.to_numeric(y)
            st.info(
                "íƒ€ê¹ƒ ë³€ìˆ˜ê°€ ë¬¸ìí˜•ì´ì–´ì„œ ìˆ«ìë¡œ ë³€í™˜í•˜ì—¬ ê´€ë ¨ë„ë¥¼ ê³„ì‚°í–ˆìŠµë‹ˆë‹¤. "
                "í´ë˜ìŠ¤ê°€ 0/1ì²˜ëŸ¼ ì´ì§„ì¼ ë•Œ í•´ì„ì´ ë” ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤."
            )
        except Exception:
            st.info(
                "í˜„ì¬ íƒ€ê¹ƒ ë³€ìˆ˜ê°€ ë¬¸ìí˜•ì´ê³  ìˆ«ìë¡œ ë³€í™˜í•˜ê¸° ì–´ë ¤ì›Œ, "
                "ìƒê´€ê³„ìˆ˜ ê¸°ë°˜ ê´€ë ¨ë„ëŠ” ê³„ì‚°í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            )
            return

    results = []
    for col in df.columns:
        if col == target_col:
            continue

        s = df[col]

        # ëª¨ë‘ ê²°ì¸¡ì´ë©´ ê±´ë„ˆë›°ê¸°
        if s.isna().all():
            continue

        try:
            if np.issubdtype(s.dtype, np.number):
                # ìˆ˜ì¹˜í˜•: ê·¸ëŒ€ë¡œ ìƒê´€ê³„ìˆ˜
                corr = s.corr(y)
                var_type = "ìˆ˜ì¹˜í˜•"
            else:
                # ë²”ì£¼í˜•: ì›-í•« ì¸ì½”ë”© í›„, íƒ€ê¹ƒê³¼ ìƒê´€ê³„ìˆ˜ê°€ ê°€ì¥ í° ë”ë¯¸ë¥¼ ëŒ€í‘œê°’ìœ¼ë¡œ ì‚¬ìš©
                dummies = pd.get_dummies(s, prefix=col, drop_first=True)
                if dummies.shape[1] == 0:
                    continue
                corrs = dummies.apply(lambda x: x.corr(y))
                # NaN ì œê±°
                corrs = corrs.dropna()
                if corrs.empty:
                    continue
                best_dummy = corrs.abs().idxmax()
                corr = corrs[best_dummy]
                var_type = "ë²”ì£¼í˜•"
            results.append(
                {
                    "ë³€ìˆ˜": col,
                    "ìœ í˜•": var_type,
                    "ìƒê´€ê³„ìˆ˜": corr,
                    "ì ˆëŒ“ê°’": abs(corr),
                }
            )
        except Exception:
            # ë¬¸ì œ ìƒê¸°ëŠ” ì—´ì€ ì¡°ìš©íˆ ìŠ¤í‚µ
            continue

    if not results:
        st.info("íƒ€ê¹ƒê³¼ì˜ ê´€ë ¨ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    res_df = pd.DataFrame(results)
    res_df = res_df.sort_values("ì ˆëŒ“ê°’", ascending=False)

    st.markdown("#### ğŸ¯ íƒ€ê¹ƒê³¼ ë³€ìˆ˜ë“¤ì˜ ê´€ë ¨ë„ ë­í‚¹ (ì ˆëŒ“ê°’ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ)")
    st.dataframe(
        res_df[["ë³€ìˆ˜", "ìœ í˜•", "ìƒê´€ê³„ìˆ˜"]],
        use_container_width=True,
    )

    st.caption(
        "- **ìƒê´€ê³„ìˆ˜**ì˜ ì ˆëŒ“ê°’ì´ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡, íƒ€ê¹ƒê³¼ì˜ ì„ í˜• ê´€ê³„ê°€ ê°•í•©ë‹ˆë‹¤.\n"
        "- ìˆ˜ì¹˜í˜•ì€ ì›ë˜ ê°’ ê·¸ëŒ€ë¡œ, ë²”ì£¼í˜•ì€ ì›-í•« ì¸ì½”ë”©ëœ ë”ë¯¸ ë³€ìˆ˜ ì¤‘\n"
        "  íƒ€ê¹ƒê³¼ ê°€ì¥ ê´€ë ¨ì´ í° ê°’ì„ ëŒ€í‘œ ìƒê´€ê³„ìˆ˜ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.\n"
        "- ì´ ê°’ì€ **ì •í™•í•œ ì¸ê³¼ê´€ê³„**ë¥¼ ì˜ë¯¸í•˜ì§€ ì•Šê³ , ì–´ë””ê¹Œì§€ë‚˜ "
        "íƒ€ê¹ƒê³¼ì˜ **ê´€ë ¨ ì •ë„ë¥¼ ë¹ ë¥´ê²Œ ì‚´í´ë³´ëŠ” ì§€í‘œ**ë¡œ í™œìš©í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤."
    )


def choose_features_and_target(df):
    """ì‚¬ì´ë“œë°”ì—ì„œ ë…ë¦½ë³€ìˆ˜(íŠ¹ì§•)ì™€ íƒ€ê¹ƒ(ì •ë‹µ) ë³€ìˆ˜ ì„ íƒ
       + íƒ€ê¹ƒê³¼ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ì—´ë“¤ì„ ê¸°ë³¸ ì„ íƒìœ¼ë¡œ ì¶”ì²œ
    """
    st.sidebar.subheader("2ï¸âƒ£ ì…ë ¥/íƒ€ê¹ƒ ë³€ìˆ˜ ì„ íƒ")

    all_cols = df.columns.tolist()

    target_col = st.sidebar.selectbox(
        "íƒ€ê¹ƒ(ì •ë‹µ) ë³€ìˆ˜ ì„ íƒ",
        options=["(ì„ íƒ ì•ˆ í•¨)"] + all_cols,
    )

    if target_col == "(ì„ íƒ ì•ˆ í•¨)":
        target_col = None

    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

    # ê¸°ë³¸ íŠ¹ì§• ì„ íƒ: íƒ€ê¹ƒê³¼ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ìƒìœ„ 5ê°œì˜ ìˆ˜ì¹˜í˜• ì—´
    default_features = []
    if target_col is not None and target_col in numeric_cols and len(numeric_cols) > 1:
        corr = df[numeric_cols].corr()[target_col].drop(target_col)
        top_features = (
            corr.abs()
            .sort_values(ascending=False)
            .head(5)
            .index
            .tolist()
        )
        default_features = top_features
        st.sidebar.caption(
            "â€» íƒ€ê¹ƒê³¼ ìƒê´€ê³„ìˆ˜ê°€ ë†’ì€ ìˆ˜ì¹˜í˜• ì—´ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ 5ê°œë¥¼ ê¸°ë³¸ ì„ íƒí–ˆìŠµë‹ˆë‹¤.\n"
            "   (ì–¸ì œë“ ì§€ ì•„ë˜ì—ì„œ ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)"
        )
    else:
        # íƒ€ê¹ƒì´ ìˆ˜ì¹˜í˜•ì´ ì•„ë‹ˆê±°ë‚˜, ìƒê´€ê´€ê³„ ê³„ì‚°ì´ ì–´ë ¤ìš´ ê²½ìš° â†’ ìˆ˜ì¹˜í˜• ì—´ ì „ì²´ ì¶”ì²œ
        default_features = [c for c in numeric_cols if c != target_col]

    feature_cols = st.sidebar.multiselect(
        "ì…ë ¥(íŠ¹ì§•) ë³€ìˆ˜ ì„ íƒ (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)",
        options=all_cols,
        default=default_features,
    )

    # íƒ€ê¹ƒì´ íŠ¹ì§•ì— ì„ì—¬ ìˆìœ¼ë©´ ì œê±°
    if target_col and target_col in feature_cols:
        st.sidebar.warning("íƒ€ê¹ƒ ë³€ìˆ˜ëŠ” ë…ë¦½ë³€ìˆ˜ì—ì„œ ìë™ìœ¼ë¡œ ì œì™¸ë©ë‹ˆë‹¤.")
        feature_cols = [c for c in feature_cols if c != target_col]

    return feature_cols, target_col


def infer_problem_type(y_series: pd.Series):
    """íƒ€ê¹ƒ yì˜ íƒ€ì…ê³¼ ê³ ìœ ê°’ ê°œìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì œ ìœ í˜•ì„ ì¶”ì •"""
    if y_series.dtype == "object":
        return "classification", "íƒ€ê¹ƒì´ ë¬¸ìí˜•(ë²”ì£¼í˜•) ë°ì´í„°ë¼ì„œ **ë¶„ë¥˜ ë¬¸ì œ**ë¡œ íŒë‹¨í–ˆìŠµë‹ˆë‹¤."
    unique_vals = y_series.nunique()

    if unique_vals <= 10:
        return (
            "classification",
            f"íƒ€ê¹ƒ ê°’ì˜ ì¢…ë¥˜ê°€ {unique_vals}ê°œë¡œ ë¹„êµì  ì ì–´ì„œ **ë¶„ë¥˜ ë¬¸ì œ**ë¡œ íŒë‹¨í–ˆìŠµë‹ˆë‹¤.",
        )
    else:
        return (
            "regression",
            f"íƒ€ê¹ƒì´ ìˆ˜ì¹˜í˜•ì´ê³  ê°’ì˜ ì¢…ë¥˜ê°€ ë§ì•„ì„œ **íšŒê·€ ë¬¸ì œ**ë¡œ íŒë‹¨í–ˆìŠµë‹ˆë‹¤.",
        )


def select_algorithm(problem_type: str):
    """ë¬¸ì œ ìœ í˜•ì— ë”°ë¼ ì•Œê³ ë¦¬ì¦˜ê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° UIë¥¼ êµ¬ì„±í•˜ê³  ì„ íƒ ê²°ê³¼ ë°˜í™˜"""
    st.sidebar.subheader("3ï¸âƒ£ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ ë° ì„¤ì •")

    params = {}

    if problem_type == "classification":
        algo = st.sidebar.selectbox(
            "ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ",
            ["ë¡œì§€ìŠ¤í‹± íšŒê·€", "ê²°ì •íŠ¸ë¦¬", "ëœë¤ í¬ë ˆìŠ¤íŠ¸", "K-ìµœê·¼ì ‘ ì´ì›ƒ(KNN)"],
        )

        if algo == "ë¡œì§€ìŠ¤í‹± íšŒê·€":
            params["max_iter"] = st.sidebar.slider(
                "ë°˜ë³µ íšŸìˆ˜ (max_iter)", 100, 500, 200, step=50
            )

        elif algo == "ê²°ì •íŠ¸ë¦¬":
            params["max_depth"] = st.sidebar.slider(
                "íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´ (max_depth)", 1, 20, 5
            )

        elif algo == "ëœë¤ í¬ë ˆìŠ¤íŠ¸":
            params["n_estimators"] = st.sidebar.slider(
                "íŠ¸ë¦¬ ê°œìˆ˜ (n_estimators)", 10, 200, 100, step=10
            )
            params["max_depth"] = st.sidebar.slider(
                "íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´ (max_depth)", 1, 20, 5
            )

        elif algo == "K-ìµœê·¼ì ‘ ì´ì›ƒ(KNN)":
            params["n_neighbors"] = st.sidebar.slider(
                "ì´ì›ƒ ê°œìˆ˜ (n_neighbors)", 1, 20, 5
            )

    else:  # regression
        algo = st.sidebar.selectbox(
            "íšŒê·€ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ",
            ["ì„ í˜• íšŒê·€", "ê²°ì •íŠ¸ë¦¬ íšŒê·€", "ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€", "K-ìµœê·¼ì ‘ ì´ì›ƒ íšŒê·€"],
        )

        if algo == "ê²°ì •íŠ¸ë¦¬ íšŒê·€":
            params["max_depth"] = st.sidebar.slider(
                "íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´ (max_depth)", 1, 20, 5
            )

        elif algo == "ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€":
            params["n_estimators"] = st.sidebar.slider(
                "íŠ¸ë¦¬ ê°œìˆ˜ (n_estimators)", 10, 200, 100, step=10
            )
            params["max_depth"] = st.sidebar.slider(
                "íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´ (max_depth)", 1, 20, 5
            )

        elif algo == "K-ìµœê·¼ì ‘ ì´ì›ƒ íšŒê·€":
            params["n_neighbors"] = st.sidebar.slider(
                "ì´ì›ƒ ê°œìˆ˜ (n_neighbors)", 1, 20, 5
            )

    return algo, params

def scale_features(X_train, X_test, scaler_option: str):
    """
    ì„ íƒí•œ ì˜µì…˜ì— ë”°ë¼ ì…ë ¥(íŠ¹ì§•) ë³€ìˆ˜ì— ì •ê·œí™”/ìŠ¤ì¼€ì¼ë§ì„ ì ìš©í•©ë‹ˆë‹¤.
    - 'ì•ˆ í•¨'         : ê·¸ëŒ€ë¡œ ì‚¬ìš©
    - 'í‘œì¤€í™”(StandardScaler)' : í‰ê·  0, í‘œì¤€í¸ì°¨ 1ì´ ë˜ë„ë¡ ë³€í™˜
    - 'Min-Max ìŠ¤ì¼€ì¼ë§'       : 0~1 ë²”ìœ„ë¡œ ë³€í™˜
    """
    if scaler_option == "ì•ˆ í•¨":
        return X_train, X_test  # ì•„ë¬´ ê²ƒë„ ì•ˆ í•˜ê³  ê·¸ëŒ€ë¡œ ë°˜í™˜

    if scaler_option == "í‘œì¤€í™”(StandardScaler)":
        scaler = StandardScaler()
    elif scaler_option == "Min-Max ìŠ¤ì¼€ì¼ë§":
        scaler = MinMaxScaler()
    else:
        # í˜¹ì‹œ ëª¨ë¥¼ ì˜ˆì™¸ (ê¸°ë³¸ì€ ì•„ë¬´ ê²ƒë„ ì•ˆ í•¨)
        return X_train, X_test

    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    return X_train_scaled, X_test_scaled

def build_model(problem_type: str, algo: str, params: dict):
    """ì„ íƒëœ ì•Œê³ ë¦¬ì¦˜ê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ ê°ì²´ ìƒì„±"""
    if problem_type == "classification":
        if algo == "ë¡œì§€ìŠ¤í‹± íšŒê·€":
            model = LogisticRegression(
                max_iter=params.get("max_iter", 200),
            )
        elif algo == "ê²°ì •íŠ¸ë¦¬":
            model = DecisionTreeClassifier(
                max_depth=params.get("max_depth", None),
                random_state=42,
            )
        elif algo == "ëœë¤ í¬ë ˆìŠ¤íŠ¸":
            model = RandomForestClassifier(
                n_estimators=params.get("n_estimators", 100),
                max_depth=params.get("max_depth", None),
                random_state=42,
                n_jobs=-1,
            )
        elif algo == "K-ìµœê·¼ì ‘ ì´ì›ƒ(KNN)":
            model = KNeighborsClassifier(
                n_neighbors=params.get("n_neighbors", 5),
                n_jobs=-1,
            )
        else:
            raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.")
    else:
        if algo == "ì„ í˜• íšŒê·€":
            model = LinearRegression()
        elif algo == "ê²°ì •íŠ¸ë¦¬ íšŒê·€":
            model = DecisionTreeRegressor(
                max_depth=params.get("max_depth", None),
                random_state=42,
            )
        elif algo == "ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€":
            model = RandomForestRegressor(
                n_estimators=params.get("n_estimators", 100),
                max_depth=params.get("max_depth", None),
                random_state=42,
                n_jobs=-1,
            )
        elif algo == "K-ìµœê·¼ì ‘ ì´ì›ƒ íšŒê·€":
            model = KNeighborsRegressor(
                n_neighbors=params.get("n_neighbors", 5),
                n_jobs=-1,
            )
        else:
            raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íšŒê·€ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.")

    return model


def show_classification_results(y_test, y_pred):
    """ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ ê²°ê³¼ ì¶œë ¥"""
    st.subheader("5ï¸âƒ£ ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ ê²°ê³¼ ğŸ”")

    # --- 1) ë¼ë²¨ ë° ë¦¬í¬íŠ¸ ê³„ì‚° (ìœ„/ì•„ë˜ì—ì„œ ê³µí†µ ì‚¬ìš©) ---
    labels = sorted(list(set(y_test) | set(y_pred)))

    # classification_reportë¥¼ dictë¡œ ë°›ì•„ì™€ì„œ ìˆ«ìë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì‚¬ìš©
    report = classification_report(
        y_test, y_pred, output_dict=True, zero_division=0
    )

    # ì •í™•ë„ëŠ” report["accuracy"]ì— ë“¤ì–´ ìˆìŒ
    acc = report["accuracy"]

    # ì´ì§„ ë¶„ë¥˜ë©´ "ì–‘ì„± í´ë˜ìŠ¤(ë³´í†µ 1)" ê¸°ì¤€, ì•„ë‹ˆë©´ macro í‰ê·  ì‚¬ìš©
    if len(labels) == 2:
        pos_label = 1 if 1 in labels else labels[-1]
        key = str(pos_label)
        prec = report[key]["precision"]
        rec = report[key]["recall"]
        f1 = report[key]["f1-score"]
        metric_note = f"(ì–‘ì„± í´ë˜ìŠ¤ {key} ê¸°ì¤€)"
    else:
        prec = report["macro avg"]["precision"]
        rec = report["macro avg"]["recall"]
        f1 = report["macro avg"]["f1-score"]
        metric_note = "(ëª¨ë“  í´ë˜ìŠ¤ë¥¼ ë™ì¼ ë¹„ì¤‘ìœ¼ë¡œ ë³¸ macro í‰ê· )"

    # --- 2) ìœ„ìª½ì— í° ë©”íŠ¸ë¦­ 4ê°œ í•œëˆˆì— ë³´ì—¬ì£¼ê¸° ---
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ì •í™•ë„ (accuracy)", f"{acc:.3f}")
    c2.metric(f"ì •ë°€ë„ (precision) {metric_note}", f"{prec:.3f}")
    c3.metric(f"ì¬í˜„ìœ¨ (recall) {metric_note}", f"{rec:.3f}")
    c4.metric(f"F1-score {metric_note}", f"{f1:.3f}")

    st.caption(
        "- **ì •í™•ë„(accuracy)**: ì „ì²´ ì˜ˆì¸¡ ì¤‘ì—ì„œ ë§ì¶˜ ë¹„ìœ¨\n"
        "- **ì •ë°€ë„(precision)**: 'ë§ë‹¤ê³  ì˜ˆì¸¡í•œ ê²ƒ' ì¤‘ì—ì„œ ì‹¤ì œë¡œ ë§ì€ ë¹„ìœ¨\n"
        "- **ì¬í˜„ìœ¨(recall)**: 'ì‹¤ì œë¡œ ë§ëŠ” ê²ƒ' ì¤‘ì—ì„œ ëª¨ë¸ì´ ë§ë‹¤ê³  ì°¾ì•„ë‚¸ ë¹„ìœ¨\n"
        "- **F1-score**: ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™”í‰ê·  (ë‘˜ ë‹¤ ê· í˜• ìˆê²Œ ì¢‹ì€ì§€)"
    )

    # --- 2-1) í´ë˜ìŠ¤ë³„ ìƒì„¸ ì§€í‘œ (expander) ---
    # --- 2-1) í´ë˜ìŠ¤ë³„ ìƒì„¸ ì§€í‘œ (expander) ---
    with st.expander("í´ë˜ìŠ¤ë³„ ì •ë°€ë„/ì¬í˜„ìœ¨/F1-score ìì„¸íˆ ë³´ê¸°"):
        st.text(classification_report(y_test, y_pred, zero_division=0))

        if len(labels) == 2:
            # âœ… ì´ì§„ ë¶„ë¥˜ ì„¤ëª…
            st.caption(
                "- **ì†Œìˆ˜ í´ë˜ìŠ¤(ì˜ˆ: 1)**ëŠ” ë°ì´í„°ì—ì„œ ê°œìˆ˜ëŠ” ì ì§€ë§Œ, ë†“ì¹˜ë©´ ì•ˆ ë˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. "
                "(ì˜ˆ: ì§ˆë³‘ ìˆìŒ, ì´ìƒ ì§•í›„, ë¶€ì • ê±°ë˜ ë“±)\n"
                "- ì¬í˜„ìœ¨(recall)ì´ ë‚®ìœ¼ë©´ **ì‹¤ì œë¡œ 1ì¸ ì‚¬ë¡€ë¥¼ ë§ì´ ë†“ì¹˜ê³  ìˆë‹¤**ëŠ” ëœ»ì´ê³ ,\n"
                "  ì •ë°€ë„(precision)ê°€ ë‚®ìœ¼ë©´ **ì‚¬ì‹¤ì€ 0ì¸ë° 1ì´ë¼ê³  ì˜ëª» ë¶„ë¥˜í•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤**ëŠ” ëœ»ì…ë‹ˆë‹¤.\n"
                "- ì˜ë£ŒÂ·ì•ˆì „ì²˜ëŸ¼ 'ë†“ì¹˜ë©´ ì•ˆ ë˜ëŠ” ê²½ìš°'ì—ëŠ” **ì¬í˜„ìœ¨**ì„ ë” ì¤‘ìš”í•˜ê²Œ ë³´ê³ ,\n"
                "  ê´‘ê³ Â·ìŠ¤íŒ¸ì²˜ëŸ¼ 'ê´œíˆ 1ì´ë¼ê³  í•˜ë©´ ë¶ˆí¸í•œ ê²½ìš°'ì—ëŠ” **ì •ë°€ë„**ë¥¼ ë” ì¤‘ìš”í•˜ê²Œ ë´…ë‹ˆë‹¤.\n"
                "- **F1-score**ëŠ” ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì„ í•¨ê»˜ ê³ ë ¤í•´, "
                "ë‘ ê°’ì´ ì–¼ë§ˆë‚˜ **ê· í˜• ìˆê²Œ** ì¢‹ì€ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” ì§€í‘œì…ë‹ˆë‹¤."
            )
        else:
            # âœ… ë‹¤ì¤‘ ë¶„ë¥˜ ì„¤ëª…
            st.caption(
                "- ì´ ë¬¸ì œëŠ” **ì—¬ëŸ¬ ê°œì˜ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë‹¤ì¤‘ ë¶„ë¥˜ ë¬¸ì œ**ì…ë‹ˆë‹¤.\n"
                "- ìœ„ í‘œì—ì„œ ê° í–‰ì´ í•˜ë‚˜ì˜ í´ë˜ìŠ¤ë¥¼ ë‚˜íƒ€ë‚´ë©°, ê° í´ë˜ìŠ¤ë³„ë¡œ\n"
                "  Â· ì •ë°€ë„(precision): ê·¸ í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ì—ì„œ ì‹¤ì œë¡œ ë§ì€ ë¹„ìœ¨\n"
                "  Â· ì¬í˜„ìœ¨(recall): ì‹¤ì œë¡œ ê·¸ í´ë˜ìŠ¤ì¸ ê²ƒ ì¤‘ì—ì„œ ëª¨ë¸ì´ ë§ê²Œ ì°¾ì•„ë‚¸ ë¹„ìœ¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n"
                "- **macro avg**ëŠ” ëª¨ë“  í´ë˜ìŠ¤ë¥¼ ë™ì¼í•œ ë¹„ì¤‘ìœ¼ë¡œ ë³´ê³  í‰ê· ì„ ë‚¸ ê°’ì´ë¼,\n"
                "  í´ë˜ìŠ¤ê°€ ì ê²Œ ë‚˜ì™€ë„ í•œ í´ë˜ìŠ¤ì”© ê³¨ê³ ë£¨ ì˜ ë§ì¶”ëŠ”ì§€ í™•ì¸í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n"
                "- íŠ¹ì • í´ë˜ìŠ¤ê°€ íŠ¹íˆ ì¤‘ìš”í•˜ë‹¤ë©´(ì˜ˆ: 'ìœ„í—˜', 'ì´ìƒ'), "
                "ê·¸ í´ë˜ìŠ¤ í–‰ì˜ ì •ë°€ë„/ì¬í˜„ìœ¨/F1-scoreë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚´í´ë³´ì„¸ìš”."
            )

    # --- 3) í˜¼ë™í–‰ë ¬ ê·¸ë¦¼ ---
    st.markdown("#### ğŸ”¢ í˜¼ë™í–‰ë ¬ (Confusion Matrix)")

    cm = confusion_matrix(y_test, y_pred, labels=labels)
    label_strs = [str(l) for l in labels]

    fig_cm = px.imshow(
        cm,
        x=label_strs,
        y=label_strs,
        text_auto=True,
        color_continuous_scale="Blues",
        aspect="equal",
    )
    fig_cm.update_layout(
        xaxis_title="ì˜ˆì¸¡ ê°’",
        yaxis_title="ì‹¤ì œ ê°’",
        xaxis=dict(type="category"),
        yaxis=dict(type="category"),
    )
    st.plotly_chart(fig_cm, use_container_width=True)

    # --- 4) í˜¼ë™í–‰ë ¬ & ë¶„í¬ ì„¤ëª… í…ìŠ¤íŠ¸ ---
    st.markdown(
        """
**í˜¼ë™í–‰ë ¬ & ë¶„í¬ ê·¸ë˜í”„ í•´ì„**

- **í˜¼ë™í–‰ë ¬**ì€ `ì •ë‹µ(ì‹¤ì œ ê°’)`ê³¼ `ì˜ˆì¸¡`ì„ ì§ì§€ì–´ì„œ **ì–¼ë§ˆë‚˜ ë§ì•˜ëŠ”ì§€/í‹€ë ¸ëŠ”ì§€**ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  
- **ì‹¤ì œ ë¶„í¬ vs ì˜ˆì¸¡ ë¶„í¬ ê·¸ë˜í”„**ëŠ” ëª¨ë¸ì´ ê° í´ë˜ìŠ¤ë¥¼ **ì–¼ë§ˆë‚˜ ìì£¼ ì„ íƒí–ˆëŠ”ì§€**ë¥¼ ì‹¤ì œ ë°ì´í„°ì™€ ë¹„êµí•´ì„œ ë³´ì—¬ì¤ë‹ˆë‹¤.  

ë‘ ì •ë³´ë¥¼ í•¨ê»˜ ë³´ë©´  
- ë‹¨ìˆœíˆ **ë§ì¶˜ ë¹„ìœ¨(ì •í™•ë„)**ë¿ ì•„ë‹ˆë¼,  
- **íŠ¹ì • ë‹µë§Œ ë„ˆë¬´ ë§ì´ ê³ ë¥´ëŠ” ê±´ ì•„ë‹Œì§€(í¸í–¥)**ë„ í•¨ê»˜ ì‚´í´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """
    )

    # --- 5) ì‹¤ì œ ë¶„í¬ vs ì˜ˆì¸¡ ë¶„í¬ (ë¹„ìœ¨ ë¹„êµ) ---
    st.markdown("#### ğŸ“Š ì‹¤ì œ ë¶„í¬ vs ì˜ˆì¸¡ ë¶„í¬ (ë¹„ìœ¨ ë¹„êµ)")

    actual_counts = pd.Series(y_test).value_counts()
    pred_counts = pd.Series(y_pred).value_counts()

    all_labels = sorted(set(actual_counts.index) | set(pred_counts.index))
    actual_counts = actual_counts.reindex(all_labels, fill_value=0)
    pred_counts = pred_counts.reindex(all_labels, fill_value=0)

    actual_ratio = actual_counts / actual_counts.sum()
    pred_ratio = pred_counts / pred_counts.sum()

    dist_df = pd.DataFrame({
        "í´ë˜ìŠ¤": [str(l) for l in all_labels] * 2,
        "ë¹„ìœ¨": np.concatenate([actual_ratio.values, pred_ratio.values]),
        "ë°ì´í„°": ["ì‹¤ì œ"] * len(all_labels) + ["ì˜ˆì¸¡"] * len(all_labels),
    })

    fig_compare = px.bar(
        dist_df,
        x="í´ë˜ìŠ¤",
        y="ë¹„ìœ¨",
        color="ë°ì´í„°",
        barmode="group",
        text_auto=".2f",
    )
    fig_compare.update_layout(
        yaxis=dict(range=[0, 1]),
        yaxis_title="ë¹„ìœ¨",
    )
    st.plotly_chart(fig_compare, use_container_width=True)

    st.caption(
        "ë§‰ëŒ€ê·¸ë˜í”„ì—ì„œ **ì‹¤ì œ ë¶„í¬**ì™€ **ì˜ˆì¸¡ ë¶„í¬**ì˜ ëª¨ì–‘ì´ ë¹„ìŠ·í• ìˆ˜ë¡, "
        "ëª¨ë¸ì´ ê° í´ë˜ìŠ¤ë¥¼ ë³´ë‹¤ ê· í˜• ìˆê²Œ ì˜ˆì¸¡í•˜ê³  ìˆë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )


def show_regression_results(y_test, y_pred):
    """íšŒê·€ ëª¨ë¸ í‰ê°€ ê²°ê³¼ ì¶œë ¥"""
    st.subheader("5ï¸âƒ£ íšŒê·€ ëª¨ë¸ í‰ê°€ ê²°ê³¼ ğŸ”")

    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    col1, col2 = st.columns(2)

    with col1:
        st.metric("RMSE", f"{rmse:.3f}")
        st.metric("MAE", f"{mae:.3f}")

    with col2:
        st.metric("MSE", f"{mse:.3f}")
        st.metric("RÂ²", f"{r2:.3f}")

    st.caption(
        "RMSE, MAE, MSEëŠ” **ì˜ˆì¸¡ ê°’ê³¼ ì‹¤ì œ ê°’ì˜ ì°¨ì´ê°€ ì–¼ë§ˆë‚˜ í°ì§€**ë¥¼ ë‚˜íƒ€ë‚´ê³ , "
        "RÂ²ëŠ” **ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•˜ëŠ”ì§€**ë¥¼ ë³´ì—¬ì£¼ëŠ” ì§€í‘œì…ë‹ˆë‹¤. (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤.)"
    )

    # ì‹¤ì œ ê°’ vs ì˜ˆì¸¡ ê°’ ì‚°ì ë„
    st.markdown("#### ğŸ“ˆ ì‹¤ì œ ê°’ vs ì˜ˆì¸¡ ê°’")
    result_df = pd.DataFrame({"ì‹¤ì œ ê°’": y_test, "ì˜ˆì¸¡ ê°’": y_pred})
    fig_scatter = px.scatter(result_df, x="ì‹¤ì œ ê°’", y="ì˜ˆì¸¡ ê°’")
    # ê¸°ì¤€ì„ (ì™„ë²½ ì˜ˆì¸¡ì¼ ë•Œ y=x) ì¶”ê°€
    min_val = min(result_df["ì‹¤ì œ ê°’"].min(), result_df["ì˜ˆì¸¡ ê°’"].min())
    max_val = max(result_df["ì‹¤ì œ ê°’"].max(), result_df["ì˜ˆì¸¡ ê°’"].max())
    fig_scatter.add_shape(
        type="line",
        x0=min_val,
        y0=min_val,
        x1=max_val,
        y1=max_val,
    )
    fig_scatter.update_layout(xaxis_title="ì‹¤ì œ ê°’", yaxis_title="ì˜ˆì¸¡ ê°’")
    st.plotly_chart(fig_scatter, use_container_width=True)
    st.caption("ì ë“¤ì´ ëŒ€ê°ì„  ê·¼ì²˜ì— ëª¨ì—¬ ìˆì„ìˆ˜ë¡ **ì˜ˆì¸¡ì´ ì˜ ëœ ê²ƒ**ì…ë‹ˆë‹¤.")


def run_training_and_evaluation(
    df, feature_cols, target_col, problem_type, algo, params, test_size, scaler_option
):
    """ì „ì²´ í•™ìŠµ/í‰ê°€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    st.subheader("4ï¸âƒ£ í•™ìŠµ ë° ë°ì´í„° ë¶„í• ")

    data = df[feature_cols + [target_col]].copy()

    st.write(f"- ì„ íƒëœ ì…ë ¥(íŠ¹ì§•) ë³€ìˆ˜: **{feature_cols}**")
    st.write(f"- íƒ€ê¹ƒ(ì •ë‹µ) ë³€ìˆ˜: **{target_col}**")

    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    missing_before = data.isna().sum().sum()
    if missing_before > 0:
        st.warning(
            f"ê²°ì¸¡ì¹˜(ë¹ˆ ê°’)ê°€ ì´ {missing_before}ê°œ ë°œê²¬ë˜ì–´, "
            "í•´ë‹¹ í–‰ì„ ì œê±°í•˜ê³  í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤."
        )
        data = data.dropna()

    if data.shape[0] < 5:
        st.error("í–‰ì´ 5ê°œ ë¯¸ë§Œì´ë©´ ëª¨ë¸ í•™ìŠµì´ ì–´ë µìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    X = data[feature_cols]
    y = data[target_col]

    # ğŸ”¹ ë¶„ë¥˜ ë¬¸ì œì¸ë° íƒ€ê¹ƒì´ ì—°ì†ì ì¸ ìˆ˜ì¹˜í˜•ì´ë©´ ë¯¸ë¦¬ ì²´í¬ ğŸ”¹
    if problem_type == "classification":
        if np.issubdtype(y.dtype, np.floating):
            unique_vals = np.sort(y.unique())
            # ê°’ë“¤ì´ ì •ìˆ˜ì²˜ëŸ¼ ë³´ì´ê³ , ì¢…ë¥˜ê°€ ë§ì§€ ì•Šìœ¼ë©´ ì •ìˆ˜ ë¼ë²¨ë¡œ ë³€í™˜
            if (
                np.allclose(unique_vals, unique_vals.astype(int))
                and len(unique_vals) <= 20
            ):
                y = y.astype(int)
                st.info(
                    "íƒ€ê¹ƒ ê°’ì´ ìˆ«ì(float)ì§€ë§Œ ê°’ì˜ ì¢…ë¥˜ê°€ ì ê³  ì •ìˆ˜ì²˜ëŸ¼ ë³´ì—¬ "
                    "**ë²”ì£¼í˜• ë¼ë²¨(ì •ìˆ˜)** ë¡œ ìë™ ë³€í™˜í•˜ì—¬ ë¶„ë¥˜ ë¬¸ì œë¡œ í•™ìŠµí•©ë‹ˆë‹¤."
                )
            else:
                st.error(
                    "í˜„ì¬ ì„ íƒí•œ íƒ€ê¹ƒ ë³€ìˆ˜ëŠ” **ì—°ì†ì ì¸ ìˆ˜ì¹˜í˜• ë°ì´í„°**ë¡œ ë³´ì…ë‹ˆë‹¤.\n\n"
                    "- ë¶„ë¥˜(Random Forest, ë¡œì§€ìŠ¤í‹± íšŒê·€ ë“±)ëŠ” ì´ëŸ° íƒ€ê¹ƒì— ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                    "- ğŸ‘‰ ì‚¬ì´ë“œë°”ì—ì„œ ë¬¸ì œ ìœ í˜•ì„ **'íšŒê·€'**ë¡œ ë°”ê¾¸ê±°ë‚˜,\n"
                    "  ë˜ëŠ” **ë²”ì£¼í˜•(í´ë˜ìŠ¤)** íƒ€ê¹ƒ ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
                )
                return

    # ë²”ì£¼í˜•(ë¬¸ìí˜•) íŠ¹ì§•ì„ ì›-í•« ì¸ì½”ë”©
    X_encoded = pd.get_dummies(X, drop_first=True)

    # íšŒê·€ ë¬¸ì œì—ì„œ yê°€ ìˆ«ìê°€ ì•„ë‹ˆë©´ ë³€í™˜ ì‹œë„
    if problem_type == "regression" and not np.issubdtype(y.dtype, np.number):
        try:
            y = pd.to_numeric(y)
        except Exception:
            st.error(
                "íšŒê·€ ë¬¸ì œì—ì„œëŠ” íƒ€ê¹ƒ ë³€ìˆ˜ê°€ ìˆ«ìí˜•ì´ì–´ì•¼ í•©ë‹ˆë‹¤. "
                "ë‹¤ë¥¸ íƒ€ê¹ƒì„ ì„ íƒí•˜ê±°ë‚˜ ë¬¸ì œ ìœ í˜•ì„ ë¶„ë¥˜ë¡œ ë°”ê¿”ë³´ì„¸ìš”."
            )
            return

    X_train, X_test, y_train, y_test = train_test_split(
        X_encoded, y, test_size=test_size, random_state=42
    )

    # ğŸ”¹ ì„ íƒí•œ ì˜µì…˜ì— ë”°ë¼ ì •ê·œí™”/ìŠ¤ì¼€ì¼ë§ ì ìš©
    X_train, X_test = scale_features(X_train, X_test, scaler_option)

    st.write(f"- í•™ìŠµ(train) ë°ì´í„° í–‰ ê°œìˆ˜: **{X_train.shape[0]}**")
    st.write(f"- í…ŒìŠ¤íŠ¸(test) ë°ì´í„° í–‰ ê°œìˆ˜: **{X_test.shape[0]}**")

    if scaler_option != "ì•ˆ í•¨":
        st.info(
            f"ì…ë ¥(íŠ¹ì§•) ë³€ìˆ˜ì— **{scaler_option}**ì„ ì ìš©í•´ "
            "íŠ¹ì§•ë“¤ì˜ í¬ê¸°(ìŠ¤ì¼€ì¼)ë¥¼ ë§ì¶˜ ë’¤ ëª¨ë¸ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.\n"
            "íŠ¹íˆ **K-ìµœê·¼ì ‘ ì´ì›ƒ(KNN), ë¡œì§€ìŠ¤í‹± íšŒê·€**ì²˜ëŸ¼ ê±°ë¦¬/í¬ê¸°ì— ë¯¼ê°í•œ ì•Œê³ ë¦¬ì¦˜ì—ì„œ ë„ì›€ì´ ë©ë‹ˆë‹¤."
        )

    model = build_model(problem_type, algo, params)

    # ëª¨ë¸ í•™ìŠµ
    model.fit(X_train, y_train)
    st.success("âœ… ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    # ì˜ˆì¸¡ ë° í‰ê°€
    y_pred = model.predict(X_test)

    if problem_type == "classification":
        show_classification_results(y_test, y_pred)
    else:
        show_regression_results(y_test, y_pred)


# ---------------------------------------------
# ë©”ì¸ ì•±
# ---------------------------------------------
def main():
    # í•™ìŠµ ì™„ë£Œ ì—¬ë¶€ë¥¼ session_stateì— ì €ì¥ (ì²˜ìŒì—ëŠ” False)
    if "trained" not in st.session_state:
        st.session_state["trained"] = False

    st.title("ğŸ¤– ì§€ë„í•™ìŠµ ì‹¤ìŠµ ì›¹ ì•±")
    st.write(
        """
        ì´ ì•±ì€ **CSV ë°ì´í„°ë¥¼ ì—…ë¡œë“œ â†’ íŠ¹ì§•/íƒ€ê¹ƒ ì„ íƒ â†’ ìƒê´€ê´€ê³„ íƒìƒ‰ â†’ ë¶„ë¥˜/íšŒê·€ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ â†’ ëª¨ë¸ í•™ìŠµ/í‰ê°€**ê¹Œì§€  
        ì§€ë„í•™ìŠµ(supervised learning)ì˜ ì „ì²´ íë¦„ì„ ì§ì ‘ ì²´í—˜í•´ë³¼ ìˆ˜ ìˆë„ë¡ ë§Œë“  êµìœ¡ìš© ë„êµ¬ì…ë‹ˆë‹¤.
        """
    )
    # ğŸ‘‡ ì—¬ê¸° ì¶”ê°€í•˜ì„¸ìš”
    st.markdown(
        """
        <style>
        .made-by-footer {
            position: fixed;
            bottom: 0.5rem;
            right: 1rem;
            color: #888888;
            font-size: 0.8rem;
            z-index: 9999;
        }
        </style>
        <div class="made-by-footer">
            MADE BY ì •ìœ¤T ğŸ’™
        </div>
        """,
        unsafe_allow_html=True,
    )
    
    st.info(
        "- **ë…ë¦½ë³€ìˆ˜(ì…ë ¥/íŠ¹ì§•)**: ëª¨ë¸ì´ ì°¸ê³ í•˜ëŠ” ì •ë³´ (ì˜ˆ: ê³µë¶€ ì‹œê°„, ë‚˜ì´, í‚¤)\n"
        "- **ì¢…ì†ë³€ìˆ˜(íƒ€ê¹ƒ/ì •ë‹µ)**: ëª¨ë¸ì´ ë§íˆê³  ì‹¶ì€ ê°’ (ì˜ˆ: ì‹œí—˜ ì ìˆ˜, í•©ê²©/ë¶ˆí•©ê²©)\n"
        "- ë¶„ë¥˜ ëª¨ë¸ì€ 'ë¼ë²¨(ë²”ì£¼)'ë¥¼ ë§ì¶”ëŠ” ë¬¸ì œ, íšŒê·€ ëª¨ë¸ì€ 'ìˆ«ì'ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤."
    )

    # -----------------------------------------
    # 1. ë°ì´í„° ì—…ë¡œë“œ
    # -----------------------------------------
    st.sidebar.header("0ï¸âƒ£ CSV ë°ì´í„° ì—…ë¡œë“œ")

    uploaded_file = st.sidebar.file_uploader(
        "CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["csv"]
    )

    if uploaded_file is None:
        st.warning("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ CSV íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”. ğŸ˜Š")
        st.stop()

    # ë°ì´í„° ë¡œë“œ
    df = load_data(uploaded_file)
    
    if df is None or df.empty:
        st.error("CSV íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ê±°ë‚˜, ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        st.stop()

    #    í•™ìŠµ í›„ì—ëŠ” ìˆ¨ê²¨ì„œ í‰ê°€ ê²°ê³¼ê°€ ìœ„ìª½ì— ë°”ë¡œ ë³´ì´ë„ë¡ ì²˜ë¦¬
    if not st.session_state["trained"]:
        # 1ï¸âƒ£ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ë° ìš”ì•½
        show_data_overview(df)

        # 2ï¸âƒ£ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
        show_correlation_heatmap(df)

    # -----------------------------------------
    # 2. íŠ¹ì§•/íƒ€ê¹ƒ ì„ íƒ
    # -----------------------------------------
    feature_cols, target_col = choose_features_and_target(df)

    if target_col is None:
        st.warning("íƒ€ê¹ƒ(ì •ë‹µ) ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        st.stop()

    if not feature_cols:
        st.warning("ìµœì†Œ 1ê°œì˜ ì…ë ¥(íŠ¹ì§•) ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        st.stop()

    # íƒ€ê¹ƒê³¼ì˜ ìƒê´€ê´€ê³„ í‘œ (ìˆ˜ì¹˜í˜• íƒ€ê¹ƒì¼ ë•Œ)
    show_target_correlations(df, target_col)

    # -----------------------------------------
    # 3. ë¬¸ì œ ìœ í˜• ìë™/ìˆ˜ë™ ì„¤ì •
    # -----------------------------------------
    y = df[target_col]
    inferred_type, reason = infer_problem_type(y)

    st.sidebar.subheader("3ï¸âƒ£ ë¬¸ì œ ìœ í˜• ì„¤ì •")
    st.sidebar.info(f"ìë™ íŒë‹¨ ê²°ê³¼: **{inferred_type}** ë¬¸ì œë¡œ ì¶”ì •ë¨\n\nì‚¬ìœ : {reason}")

    problem_choice = st.sidebar.radio(
        "ë¬¸ì œ ìœ í˜• ì„ íƒ",
        options=["ìë™ íŒë‹¨", "ë¶„ë¥˜", "íšŒê·€"],
        index=0,
        help="ìë™ íŒë‹¨ì´ ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ë©´ ì§ì ‘ ë¶„ë¥˜/íšŒê·€ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )

    if problem_choice == "ìë™ íŒë‹¨":
        problem_type = inferred_type
    elif problem_choice == "ë¶„ë¥˜":
        problem_type = "classification"
    else:
        problem_type = "regression"

    # -----------------------------------------
    # 4. ì•Œê³ ë¦¬ì¦˜ ì„ íƒ & í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
    # -----------------------------------------
    algo, params = select_algorithm(problem_type)

    # train/test ë¹„ìœ¨ ì„¤ì •
    st.sidebar.subheader("4ï¸âƒ£ í•™ìŠµ/í‰ê°€ ë¹„ìœ¨ ì„¤ì •")
    test_size = st.sidebar.slider(
        "í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨ (0.2 = 20%)",
        min_value=0.2,
        max_value=0.4,
        value=0.3,
        step=0.05,
    )
    st.sidebar.caption(
        "í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ë”°ë¡œ ë–¼ì–´ë†“ëŠ” ë°ì´í„°ì…ë‹ˆë‹¤."
    )

    # ì •ê·œí™”/ìŠ¤ì¼€ì¼ë§ ì„ íƒ
    st.sidebar.subheader("5ï¸âƒ£ ì •ê·œí™” / ìŠ¤ì¼€ì¼ë§ ì„¤ì •")
    scaler_option = st.sidebar.radio(
        "ì…ë ¥(íŠ¹ì§•) ë³€ìˆ˜ ì •ê·œí™” ë°©ë²• ì„ íƒ",
        ["ì•ˆ í•¨", "í‘œì¤€í™”(StandardScaler)", "Min-Max ìŠ¤ì¼€ì¼ë§"],
        index=0,
        help=(
            "ëª¨ë¸ì— ë„£ê¸° ì „ì— ì…ë ¥ ë³€ìˆ˜ë“¤ì˜ í¬ê¸°ë¥¼ ë¹„ìŠ·í•œ ë²”ìœ„ë¡œ ë§ì¶°ì¤ë‹ˆë‹¤.\n"
            "KNN, ë¡œì§€ìŠ¤í‹± íšŒê·€ì²˜ëŸ¼ ê±°ë¦¬/í¬ê¸°ì— ë¯¼ê°í•œ ì•Œê³ ë¦¬ì¦˜ì—ì„œ íŠ¹íˆ ì¤‘ìš”í•©ë‹ˆë‹¤."
        ),
    )

    # -----------------------------------------
    # 5. ëª¨ë¸ í•™ìŠµ ë²„íŠ¼
    # -----------------------------------------
    st.sidebar.subheader("6ï¸âƒ£ ëª¨ë¸ í•™ìŠµ ì‹¤í–‰")
    if st.sidebar.button("ğŸš€ ëª¨ë¸ í•™ìŠµí•˜ê¸°"):
        st.session_state["trained"] = True

    # -----------------------------------------
    # 6. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ê²°ê³¼ í‘œì‹œ
    # -----------------------------------------
    if st.session_state["trained"]:
        run_training_and_evaluation(
            df=df,
            feature_cols=feature_cols,
            target_col=target_col,
            problem_type=problem_type,
            algo=algo,
            params=params,
            test_size=test_size,
            scaler_option=scaler_option,
        )

        # (ì„ íƒ) ë‹¤ì‹œ 1ë²ˆ/2ë²ˆ ë³´ê³  ì‹¶ì„ ë•Œë¥¼ ìœ„í•œ ë²„íŠ¼
        if st.button("ğŸ”„ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°/ìƒê´€ê´€ê³„ ë‹¤ì‹œ ë³´ê¸°"):
            st.session_state["trained"] = False
            st.experimental_rerun()
    else:
        st.info(
            "ì‚¬ì´ë“œë°”ì—ì„œ **ğŸš€ ëª¨ë¸ í•™ìŠµí•˜ê¸°** ë²„íŠ¼ì„ ëˆ„ë¥´ë©´, "
            "ì•„ë˜ì— ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤."
        )


if __name__ == "__main__":
    main()
